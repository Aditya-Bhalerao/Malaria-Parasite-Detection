{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 00:30:20.586120: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-17 00:30:20.673731: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 00:30:20.673827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 00:30:20.675695: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 00:30:20.687591: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-17 00:30:20.689635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 00:30:22.998244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications import resnet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n",
      "./data/Uninfected\n",
      "./data/Parasitized\n",
      "./data/cell_images\n",
      "./data/cell_images/Uninfected\n",
      "./data/cell_images/Parasitized\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(parasitized, uninfected):\n",
    "    \n",
    "    parasitized = [\"./data/Parasitized\" + '/' +  parasitize for parasitize in parasitized]\n",
    "    uninfected = [\"./data/Uninfected\" + '/' +  uninfect for uninfect in uninfected]\n",
    "\n",
    "    labels = len(parasitized) * ['parasitized'] + len(uninfected) * ['uninfected']\n",
    "    data = parasitized + uninfected\n",
    "\n",
    "    return pd.DataFrame({'Image_Path': data , 'Labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep(os.listdir(\"./data/Parasitized/\"), os.listdir(\"./data/Uninfected/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (27558, 2)\n",
      "\n",
      "Head of the DataFrame:\n",
      "                                          Image_Path       Labels\n",
      "0  ./data/Parasitized/C137P98ThinF_IMG_20151005_1...  parasitized\n",
      "1  ./data/Parasitized/C133P94ThinF_IMG_20151004_1...  parasitized\n",
      "2  ./data/Parasitized/C39P4thinF_original_IMG_201...  parasitized\n",
      "3  ./data/Parasitized/C70P31_ThinF_IMG_20150819_1...  parasitized\n",
      "4  ./data/Parasitized/C132P93ThinF_IMG_20151004_1...  parasitized\n",
      "\n",
      "Tail of the DataFrame:\n",
      "                                              Image_Path      Labels\n",
      "27553  ./data/Uninfected/C145P106ThinF_IMG_20151016_1...  uninfected\n",
      "27554  ./data/Uninfected/C72P33_ThinF_IMG_20150815_10...  uninfected\n",
      "27555  ./data/Uninfected/C101P62ThinF_IMG_20150918_15...  uninfected\n",
      "27556  ./data/Uninfected/C7NthinF_IMG_20150611_105444...  uninfected\n",
      "27557  ./data/Uninfected/C183P144NThinF_IMG_20151201_...  uninfected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "print(\"\\nHead of the DataFrame:\")\n",
    "print(df.head())\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 00:30:54.128238: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "552/552 [==============================] - 115s 200ms/step - loss: 0.4710 - accuracy: 0.7828 - val_loss: 0.1702 - val_accuracy: 0.9392\n",
      "Epoch 2/30\n",
      "552/552 [==============================] - 130s 235ms/step - loss: 0.2040 - accuracy: 0.9335 - val_loss: 0.1760 - val_accuracy: 0.9535\n",
      "Epoch 3/30\n",
      "552/552 [==============================] - 127s 231ms/step - loss: 0.1712 - accuracy: 0.9451 - val_loss: 0.1775 - val_accuracy: 0.9433\n",
      "Epoch 4/30\n",
      "552/552 [==============================] - 127s 230ms/step - loss: 0.1538 - accuracy: 0.9508 - val_loss: 0.1571 - val_accuracy: 0.9540\n",
      "Epoch 5/30\n",
      "552/552 [==============================] - 106s 193ms/step - loss: 0.1402 - accuracy: 0.9541 - val_loss: 0.1449 - val_accuracy: 0.9544\n",
      "Epoch 6/30\n",
      "552/552 [==============================] - 103s 187ms/step - loss: 0.1338 - accuracy: 0.9563 - val_loss: 0.1510 - val_accuracy: 0.9578\n",
      "Epoch 7/30\n",
      "552/552 [==============================] - 102s 184ms/step - loss: 0.1231 - accuracy: 0.9595 - val_loss: 0.1572 - val_accuracy: 0.9528\n",
      "Epoch 8/30\n",
      "552/552 [==============================] - 98s 177ms/step - loss: 0.1210 - accuracy: 0.9602 - val_loss: 0.1342 - val_accuracy: 0.9562\n",
      "Epoch 9/30\n",
      " 84/552 [===>..........................] - ETA: 1:20 - loss: 0.0977 - accuracy: 0.9688"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(file_paths, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load and preprocess images\n",
    "X = load_images(df['Image_Path'])\n",
    "y = df['Labels']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build an improved CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "model.fit(X_train, (y_train == 'parasitized').astype(int), epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Extract features from the CNN model\n",
    "cnn_features_train = model.predict(X_train)\n",
    "cnn_features_test = model.predict(X_test)\n",
    "\n",
    "# Reshape features for SVM\n",
    "cnn_features_train_flat = cnn_features_train.reshape(cnn_features_train.shape[0], -1)\n",
    "cnn_features_test_flat = cnn_features_test.reshape(cnn_features_test.shape[0], -1)\n",
    "\n",
    "# List of kernel types\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "# Train and evaluate SVM models for each kernel\n",
    "for kernel_type in kernels:\n",
    "    # Build an SVM model\n",
    "    svm_model = SVC(kernel=kernel_type)\n",
    "    svm_model.fit(cnn_features_train_flat, (y_train == 'parasitized'))\n",
    "\n",
    "    # Predict using the SVM model\n",
    "    svm_predictions = svm_model.predict(cnn_features_test_flat)\n",
    "\n",
    "    # Evaluate the SVM model for each kernel\n",
    "    accuracy = accuracy_score((y_test == 'parasitized'), svm_predictions)\n",
    "    print(f\"Accuracy of the SVM model (kernel: {kernel_type}): {accuracy*100}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
